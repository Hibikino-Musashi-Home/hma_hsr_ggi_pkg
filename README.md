# これは
Hibikino-Musashi@HomeのRoboCup@Home DSPL Go Get It Unknown Enviromentタスク用ROSパッケージ  

# 手法
音声情報・マニピュレータ情報から地点・物体の学習を行う．  
このタスクは学習時間が短いため，目標性能の確保にビックデータが必要な関数ベースの機械学習を避け，
プロトタイプとの距離比較で認識を行い，学習回数の削減を図っている．  

## 学習時
### 音声情報
話者の英語音声をGoogle ChromeのWeb Speech APIを経由し，文字起こしする．  
文字起こしされたものを，NLTK（Natural Language Toolkit）のCMU Pronouncing Dictionaryを用いて音素記号化する．  
地点ごとに与えられた複数のキーワードの音素を保存する．  

### マニピュレータ情報
オペレータに物体を渡してもらい，低トルクでエンドエフェクタを閉じ，マニピュレータの力センサにより重量を計測する．  
また同時に，エンドエフェクタ開度を計測することで物体のサイズを推定する．  
次に，高トルクでエンドエフェクタを閉じ，低トルク時のエンドエフェクタ開度と比較することで，物体の変形率[rad/torque]を推定する．  
これら，重量・サイズ・変形率のベクトルを物体ごとに保存する．


## 実行時
### 音声情報
学習時と同様に，音素化まで行う．  
次に，学習時の音素記号とのレーベンシュタイン距離を求め，閾値以下になった場合，命令文にキーワードが含まれているとカウントする．  
最もキーワードが一致した地点を候補とし，オペレータに移動許可を求める．  


### マニピュレータ情報
地点に到着後，一般物体検出によって検出された物体に対して把持動作を行い，重量・サイズ・変形率を求める．  
そして，学習済のベクトルと比較し，ユークリッド距離が閾値以下の場合その地点にて学習された物体とし，オペレータに持ち帰る．  
